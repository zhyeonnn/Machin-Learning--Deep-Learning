#### 인공지능을 구현하는 방법
- 머신러닝, 딥러닝이 있다.

#### 인공지능 > 머신러닝 > 딥러닝
| 분류 |머신러닝|딥러닝|
|:------:|:------:|:---:|
||인공 신경망, 서포트 벡터 머신, 결정 트리|CNN, RNN, RBM|
||주어진 데이터를 인간이 먼저 처리한다.(전처리) <div> ex) 이미지 데이터 -> 인간이 학습 데이터를 컴퓨터가 인식할 수 </div>있도록 (=숫자로) 준비해줘야 함|대량의 데이터를 신경망에 적용하면 컴퓨터가 <div>스스로 분석한 후 답을 찾는다.</div>|
||범용적인 목적을 위해 제작된 것이기 때문에 <div>데이터 특징을 스스로 추출하지 못한다.</div>||
|동작원리|입력 데이터에 알고리즘을 적용하여 <div>예측을 수행하는 방식으로 동작한다.</div>|정보를 전달하는 신경망을 사용하여 데이터 특징<div> 및 관계를 해석하는 방식이다.</div>|
|재사용|동일한 유형의 데이터 분석을 위한 <div>재사용은 불가능하다.(??)</div>|구현된 알고리즘은 동일한 유형의 데이터를<div> 분석하는 데 재사용된다.</div>|
|데이터|수천개의 데이터가 필요하다.|수백만 개이상의 데이터가 필요하다.|
|훈련 시간|단시간|장시간 훈련할 수 있다.|
|결과|점수, 분류 등의 숫자값|점수, 텍스트, 소리 등 전부 가능하다.|

# 머신러닝
- 학습 단계, 예측 단계로 구분된다.

|학습 단계|예측 단계|
|:------:|:------:|
|학습 데이터를 대상으로 학습시키고 결과로 모형이 생성된다.|학습 단계에서 생성된 모형에 새로운 데이터를 적용하여 결과를 예측한다.|

#### 전체 과정 : 데이터를 통한 학습 -> 모형 생성 -> 모형에 새로운 데이터 적용 -> 결과 예측
13p 참고
*특성 추출 : 인간이 컴퓨터가 데이터를 인지할 수 있도록 변환하는 작업, 특성을 인간이 변환하는 작업이다.

- 주요 구성 요소는 데이터와 모델(모형)이다.
- 데이터 수집 후 훈련을 위해 <b>훈련 데이터셋</b>과 <b>검증 데이터셋</b> 용도를 분리해서 사용해야 한다.
- 보통 데이터의 80%는 훈련용, 20%는 검증용으로 분리한다.(이렇게 사용은 하지만 어떠한 데이터가 20%에 몰려있다면 결과가 일반화될 수 있다는 단점이 있기도 하다.)
- 훈련 데이터가 나쁘면 실제 현상의 특성을 제대로 반영할 수 없기 때문에 데이터의 특징이 잘 반영된 훈련 데이터를 확보해야 한다.
- <b>모델(모형)</b>은 학습 단계에서 얻은 최종 결과물이면서 가설이라고도 한다.
17p
- ### 모델(가설)을 선택하여 학습 및 평가하고 평가를 바탕으로 모델을 업데이트한다.(??? 이건 머신 러닝이 알아서 하는 일인가???)

### 머신 러닝의 학습 알고리즘(지도 학습, 비지도 학습, 강화 학습)
|지도 학습|비지도 학습|
|:------:|:------:|
|정답을 알려주고 다음 정답을 예측할 수 있도록 학습시키는 방법이다.|정답을 알려주지 않고 특징(다리가 짧은 초식 동물)이 비슷한 데이터를<div>(토끼, 다람쥐) 클러스터링(범주화)하여 예측하는 방법이다.</div>|
|주어진 데이터에 대해 명확하게 분류가 가능하다.<div>(정확한 정답을 보여준다.)</div>|유사도 기반으로 특징이 유사한 데이터끼리<div>클러스터링으로 묶어서 분류한다.</div> <div>(정답이 하나이상일 수 있다.정답 하나를 선택하는게 아니라 묶음 전체로 분류한다.)</div>|

22p
= 지도학습-> 선 / 비지도학습 -> 원형(묶음)
## 강화 학습
- 자신의 행동에 대한 보상을 받으며 학습을 진행한다.
- ex) 게임(쿠키런 : 쿠키(=게이머)가 에이전트, 게임 배경이 환경이 된다.)에이전트가 환경에 따라 보상을 얻는다.동전이나 젤리를 취득하면 몸집이 커지는 등의 보상을 얻는 것이다.
- 강화학습은 보상이 커지는 행동을 자주 하도록 하고, 보상이 줄어드는 행동은 덜하도록 학습을 진행해야 한다.

## 지도 학습(분류, 회귀)
|분류|회귀|
|:------:|:------:|
|주어진 데이터를 정해진 범주에 따라 분류|데이터들의 특성을 기준으로 연속된 값을 <div>그래프로 표현하여 예측할 때 사용된다.</div>|
|분류|그래프로 표현하여 예측|
|이산형 데이터|연속형 데이터|
|훈련 데이터의 레이블 중 하나를 예측 <div>->데이터 안에 있는 클래스로만 나누어진다.</div>|숫자값으로만 나오고 최대한 정확히 예측|

+추가)
- 회귀는 선에 가까울수록 예측이 잘된 것이다.(선은 모델이 예측한 선, 점은 실제 데이터 위치)

### K-최근접 이웃(K-nearest neighbor)
`iris.iphb`
- 새로운 입력을 받았을 때 기존 클러스터에서 모든 데이터와 인스턴스 기반 거리를 측정한 후 가장 많은 속성을 가진 클러스터에 할당되는 분류 알고리즘이다.
- 즉, 새로운 입력 데이터의 주변에 가장 많은 속성을 가진 분류에 할당된다.

### 서포트 벡터 머신(SVM)
`iris_3.iphb`
- 분류되지 않은 새로운 데이터가 나타나면 결정 경계를 기준으로 경계의 어느 쪽에 속하는지 분류하는 모델
- 주어진 데이터에 대한 분류
- 커널만 적절히 선택하면 정확도가 좋게 나온다

<img width="50%" height="572" alt="image" src="https://github.com/user-attachments/assets/7f44490f-e4c8-44d1-895e-e21988b78165" />

- 선형, 비선형으로 분류 지원
- 선형으로 분류할 수 없을 때 비선형 분류를 한다.
  #### 비선형 분류의 문제를 해결하는 방법
  - 저차원(평면)에서 고차원(입체)으로 보낸 뒤 나누어 선형으로 분류할 수 있게된다. -> 수학적 계산으로 성능에 문제 발생 가능성 -> 문제 해결을 위해 도입된 <b>'커널 트릭'</b>

<img width="50%" height="743" alt="image" src="https://github.com/user-attachments/assets/4ad996c7-9866-4a96-889b-af21b5c89616" />

  #### 결정 경계
  - 데이터를 분류하기 위한 기준선
  - 결정 경계는 데이터가 분류된 클래스에서 최대한 멀리 떨어져있을 때 성능이 가장 좋다
  #### 마진
  - 결정 경계와 서포트 벡터 사이의 거리
  #### 서포트 벡터
  - 결정 경계와 가까이 있는 데이터들을 의미
  - 최적의 결정 경계는 마진을 최대로 해야 한다.
  #### 하드 마진
  - 이상치를 허용하지 않는 것
  #### 소프트 마진
  - 어느 정도의 이상치들이 마진 안에 포함되는 것

- #### 커널트릭
  #### 선형 커널
  - 선형 모델을 위한 커널
  #### 가우시안 RBF커널, 다항식 커널
  - 비선형을 위한 커널
  - 벡터 내적을 계산한 후 고차원으로 보내는 방법(연산량 줄였음)
  #### 가우시안 RBF커널
  - 입력 벡터를 차원이 무한한 고차원으로 매핑하는 것
  - 가우시안은 차수에 제한없이 무한한 확장이 가능하다

### 결정 트리
<img width="50%" height="413" alt="image" src="https://github.com/user-attachments/assets/b23d25d5-4131-40e6-ace9-05ca22bfa6d9" />

`titanic.iphb`
- 이상치가 많은 값으로 구성된 데이터셋을 다룰 때 사용
-  데이터를 분류하거나 결과값을 예측하는 분석 방법
- 1차 분류에서 순도 증가, 불순도와 불확실성 감소
- #### 순도
  - 일정 범주 안에서 같은 종류의 데이터만 모여있는 상태
- #### 불순도
  - 다른 데이터도 섞여있는 상태
- #### 불확실성을 계산하는 방법
  #### 1. 엔트로피
   - 확률의 불확실성을 수치로 나타낸 것
   - 엔트로피가 높을수록 불확실성이 높다
  #### 2. 지니 계수
   - 불순도를 측정하는 지표
   - 데이터의 통계적 분산 정도를 정량화해서 표현
   - 지니계수가 높을수록 데이터가 분산되어 있음
   - 엔트로피보다 계산이 빨라서 결정 계수에서 많이 사용한다

### 회귀
- 변수 두개가 주어졌을 때 한 변수에서 예측하거나 두 변수의 관계를 규명하는 데 사용

|변수 유형|변수명|
|:------:|:------:|
|영향을 미칠 것(영향을 주는 것)으로 예상되는 변수|독립변수|
|영향을 받을 것으로 예상되는 변수|종속변수|

### 로지스틱 회귀
`digits.py`
- 주어진 데이터에 대한 확신이 없거나 향후 추가적으로 훈력 데이터셋을 수집하여 모델을 훈련시킬 수 있는 환경에서 유용
- 각 집단에 속하는 확률의 추정치는 0에서 1사이
- 0.5를 기준으로 분류한다.
|일반적인 회귀분석|로지스틱 회귀분석|
|:------:|:------:|
|연속형 변수|이산형 변수|
|최소제곱법|최대우도법|
|F-테스트, t-테스트|X제곱 테스트|

    #### 최소제곱법
    - 실제값에서 예측값을 뺀 후 제곱

<img width="50%" height="736" alt="image" src="https://github.com/user-attachments/assets/101391de-a2d3-41a7-a603-0a713be5d491" />
    
    #### 최대 우도법
    - 우도(가능도) : 여러 가능한 가설을 평가할 수 있는 척도
    - 최대우도 : 나타난 결과에 해당하는 가설마다 계산된 우도 값 중 가장 큰 값(일어날 가능성이 가장 큰 것)
    - 최대우도법은 즉, 최대우도 추정치, 최대 가능성 추정량을 말한다.

### 선형 회귀

    
# 딥러닝
- 인간의 신경망 원리를 모방한 심층 신경망 이론을 기반으로 고안된 것이다.
- 인간의 뇌가 엄청난 뉴런과 시냅스로 구성되어 있다. 컴퓨터에도 뉴런과 시냅스 개념을 적용했다.
- 복잡하게 연결된 수많은 뉴런을 병렬 연산하여(동시에 연산이 가능하게) 기존에 컴퓨터가 수행하지 못했던 음성, 영상 인식 등의 처리를 가능하게 하였다.
28p참고

### 딥러닝의 학습과정
30p
#### 데이터 준비 방법(데이터를 쉽게 구할 수 있는 방법)
1. 텐서플로(tnesorflow)나 캐라스(keras)에서 제공하는 데이터셋을 사용하는 것이다.
  - 제공되는 데이터들은 이미 전처리가 되어있기 때문에 바로 사용할 수 있다.
2. 캐글(kaggle)같은 곳에 공개된 데이터를 사용하는 것이다.
  - 국내의 공개 데이터들도 사용할 수 있으나 상당히 많은 전처리를 해야하기 때문에 캐글같은 플랫폰에서 제공되는 데이터를 활용하면 사용하기가 편리하다.
  - 캐글의 단점은 공용데이터이기 때문에 데이터들을 많이 공개하지 않아서 데이터 양이 적다.

#### 모델 정의
- 모델 정의 단계에서 신경망을 생성한다.
- 은닉층의 개수가 많을수롣 성능은 좋아지지만 과적합이 발생할 확률이 높다.(은닉층과 과접합은 서로 관계가 있다.)

#### 모델 컴파일
- 컴파일 단계에서 데이터 형태에 따라 활성화 함수, 손실 함수, 옵티마이저를 선택할 수 있다.
- 훈련 데이터셋 형태가 연속형이면 평균 제곱 오차를 사용한다.(사용할 수 있다?)
- 훈련 데이터셋 형태가 이진 분류라면 크로스 엔트로피를 사용한다.
- 과접합을 피할 수 있는 활성화 함수 및 옵티마이저 선택이 중요하다???

#### 모델 훈련
- 훈련 단계에서는 한 번에 처리할 데이터양을 지정한다.
- 한 번에 처리할 데이터양이 많아지면학습 속도가 느려지고 메모리 부족 문제가 발생할 수 있다.(적당한 데이터양을 선택하는 것이 중요하다.)
- 일정한 묶음으로 나누어 처리할 수 있는 "배치"와 훈련 횟수를 정하는 "에포크"가 중요하다.
- 훈련 과정에서 값의 변화를 시각적으로 표현할 수 있도록 파라미터와 하이퍼파라미터에 대한 최적의 값을 찾을 수 있어야 한다.
	- 훈련 데이터셋 1000개에 대한 배치 크기가 20이라면 샘플 단위 20개마다 모델 가중치를 한 번씩 업데이트 시킨다는 의미 = 1000개의 데이터가 있는데 배치 크기 즉 20개의 칸을 만들었고 20개마다 모델 가중치를 1번씩 업데이트, 20->1 / 20->1+1=2 ... 20 -> 49+1=50(1000/20)이니까 20개씩 1번 가중치 업데이트면 50번 가중치가 업데이트 된다.
	- 그리고 에포크가 10이고 배치 크기가 20이라면 50번의 가중치 업데이트 하는 것을 10번 반복한다는 것이다.(즉, 500번 업데이트)
---- 업데이트가 정확히 어떤 뜻이지?
34p


성능이 좋다 = 예측을 잘한다, 정확도가 높다, 훈련 속도가 빠르다.

#### 모델 예측
- 검증 데이터셋을 생성한 모델에 적용하여 실제로 예측을 진행하는 단계(예측력이 낮다면 파라미터를 튜닝하거나 신경망 자체를 재설계해야 할 수도 있다.)


#### 핵심 구성 요소 
- 신경망, 역전파

#### 머신러닝과의 차이
- 심층 신경망을 가지고 있다는 점에서 차이가 발생한다.

- 심층 신경망에는 데이터셋의 어떤 특성들이 중요한지 스스로에게 가르쳐줄 수 있는 기능이 있다.
- 가중치 값을 업데이트하기 위한 역전파가 중요하다.
- 역전파 계산 과정에서 사용되는 미분이(오차를 각 가중치로 미분) 성능에 영향을 미치는 주요한 요소이다.
- 텐서플로를 이용하면 딥러닝 알고리즘 구현이 간단하고 편리하다.
39 40p

## 딥러닝 학습 알고리즘(지도 학습, 비지도 학습, 전이 학습, 강화 학습)
## 지도 학습
- 가장 많이 사용되는 것은 합성곱 신경망이다.
- 합성곱 신경망을 목적에 따라 이미지 분류, 이미지 인식, 이미지 분할로 분류한다.

|이미지 분류|이미지 인식|이미지 분할|
|:---:|:---:|:---:|
|이미지를 알고리즘에 입력하면 그 이미지가 어떤 클래스 레이블에 속하는지 알려주기 때문에 이미지 데이터를 유사한 것끼리 분류할 수 있다.|사진을 분석하여 그 안에 있는 사물의 종류를 인식하는 것이다.<div> ex) 의료 이미지에서 질병을 식별</div>|다양한 의료 영상에서 분할된 이미지 정보를 활용한다.|

- 시계열 데이터를 분류할 때는 순환 신경망을 사용한다.
- 시간에 따른 데이터가 있을 때는 순환 신경망을 사용하지만 역전파 과정에서는 기울기가 소멸하는 문제가 발생한다.
- 이때는 게이트를 세 개 추가한 것이 LSTM이다.(망각 게이트, 입력 게이트, 출력 게이트) -> 가장 활발히 사용되고 있다.

## 비지도 학습(워드 임베딩, 군집)
- 컴퓨터가 이해할 수 있게 자연어를 적절하게 변환해줘야 한다.
  ### 워드 임베딩
    - 단어를 벡터로 표현할 수 있다.
    - 단어 의미를 벡터화하는 워드투벡터와 글로브를 가장 많이 사용한다.
    - 번역이나 음성 인식 등 서비스에서 사용한다.
  ### 군집
    - 아무런 정보가 없는 상태에서 데이터를 분류하는 방법
    - 클러스터 안의 데이터는 매우 비슷하고, 다른 클러스터의 데이터와는 구분되도록 나누는 것이 목표이다.
      
## 전이 학습(전이 학습, 사전 학습 모델)
  
  ### 전이 학습
 - 사전에 학습이 완료된 모델을 가지고 원하는 학습에 미세 조정 기법을 이용하여 학습시키는 방법이다.
  ### 사전 학습 모델
 - 사전 학습 모델은 풀고자 하는 문제와 비슷하면서 많은 데이터로 이미 학습이 되어 있는 모델이다.
 - VGG, 인셉션, ModileNet 같은 사전 학습 모델을 사용하면 효율적인 학습이 가능하다.
