X변수에는 전체 데이터 중에 target(정답)열 제거
y변수에는 target(정답)열만 추가

배깅의 대표적인 알고리즘: 랜덤 포레스트(RandomForestClassifier)
ㄴ배깅 : 앙상블 학습 기법 중 하나,주어진 데이터셋에서 중복을 허용하여 여러 개의 샘플을 만들고 그 샘플마다 독립적으로 모델을 학습시켜 최종 예측값을 결정하는 방식

랜덤 포레스트
- 앙상블 알고리즘 중 비교적 빠른 속도
- 높은 예측 성능
- 결정 트리의 쉽고 직관적인 장점
- 여러개의 결정 트리분류가 전체 데이터에서 배깅 방식으로 각자의 데이터 샘플링을 통해 개별적 학습 수행 후 최종적으로 모든 분류기가 보팅을 통해 예측 결정을 하게 됨
ㄴ결정 트리?


n_estimators=100
ㄴ 100개의 트리를 학습
    ㄴ 트리는 뭐 하나를 보고 개수를 정하는게 아니기 때문에 기본값 100부터 늘려가면서 성능 확인해야한다
    ㄴ 트리는 정확도, 오차감소, 학습 시간, 메모리, 검증 성능 곡선 등을 결정한다 
    ㄴ 성능에 변화가 없을 때는 트리를 늘리는게 불필요

get_params()
ㄴ 하이퍼파라미터 확인, 모델이나 파이프라인의 하이퍼파라미터를 딕셔너리 형태로 반환하는 매서드
    ㄴ 하이퍼파라미터
        ㄴ 모델의 성능에 직접적인 영향을 미친다
        ㄴ 파라미터는 모델이 데이터 학습을 통해 자동으로 얻는 값, 하이퍼파라미터는 사용자가 미리 정해야하고, 학습과정에서 자동으로 갱신되지 않는 값
        ㄴ 하이퍼파라미터는 이미 고정된 설정값이 존재
ㄴ 최소한의 확인할 내용
 'max_depth': 트리 최대 깊이
 'max_features': 트리마다 고려할 특성 수 -> 과적합 방지에 중요, sqrt = 분류, 1/3 = 회귀
 'min_samples_leaf': 리프에 필요한 최소 샘플 수
 'min_samples_split': 노드를 나눌 최소 샘플 수
 'n_estimators': 트리 개수 -> 많으면 안정적이지만 느림
